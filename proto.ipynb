{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mlenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.metrics.distance import edit_distance,jaccard_distance\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv,GATConv,RGCNConv,RGATConv,SAGEConv\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import array as np_array,zeros as np_zeros,hstack as np_hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_dataset = pd.read_csv(\"./ng-datasets/fin-ds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'adult', 'original_language', 'overview', 'tagline', 'genres',\n",
       "       'production_country', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embmodel = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "def get_embs(sentences,batch_size=128):\n",
    "    global tokenizer,embmodel\n",
    "    embs = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True,max_length=256)\n",
    "        with torch.no_grad():\n",
    "            outputs = embmodel(**inputs)\n",
    "            batch_embs = outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()\n",
    "        embs.extend(batch_embs)\n",
    "    return np_array(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovw_emb = [\n",
    "    get_embs([item]) for item in mov_dataset[\"overview\"].to_list()\n",
    "]\n",
    "tag_emb = [\n",
    "    get_embs(literal_eval(item)).mean(axis=0) \n",
    "    if len(literal_eval(item)) > 1 \n",
    "    else get_embs([literal_eval(item)])[0]\n",
    "    for item in mov_dataset[\"tagline\"].to_list()\n",
    "]\n",
    "genre_emb = [\n",
    "    get_embs(literal_eval(item)).mean(axis=0) \n",
    "    if len(literal_eval(item)) > 1 \n",
    "    else get_embs([literal_eval(item)])[0]\n",
    "    for item in mov_dataset[\"genres\"].to_list()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\"adult\":1.0,\"original_language\":2.0,\"overview\":2.5,\"tagline\":3.0,\"genres\":4.0,\"year\":1.5}\n",
    "embs = {\"overview\":ovw_emb,\"tagline\":tag_emb,\"genres\":genre_emb}\n",
    "size = len(mov_dataset)\n",
    "sim_mat = np_zeros((size,size))\n",
    "for i in range(size):\n",
    "    for j in range(i + 1, size):\n",
    "        # Compute scalar feature similarity\n",
    "        scalar_features_i = np_array(\n",
    "            [\n",
    "                mov_dataset.iloc[i][\"is_adult\"] * weights[\"adult\"],\n",
    "                mov_dataset.iloc[i][\"original_language\"] * weights[\"original_language\"],\n",
    "                mov_dataset.iloc[i][\"year\"] * weights[\"year\"],\n",
    "            ]\n",
    "        )\n",
    "        scalar_features_j = np_array(\n",
    "            [\n",
    "                mov_dataset.iloc[j][\"is_adult\"] * weights[\"adult\"],\n",
    "                mov_dataset.iloc[j][\"original_language\"] * weights[\"original_language\"],\n",
    "                mov_dataset.iloc[j][\"year\"] * weights[\"year\"],\n",
    "            ]\n",
    "        )\n",
    "        scalar_similarity = cosine_similarity([scalar_features_i], [scalar_features_j])[0][0]\n",
    "        text_similarities = []\n",
    "        for feature in [\"overview\", \"tagline\", \"genres\"]:\n",
    "            emb_i = embs[feature][i] * weights[feature]\n",
    "            emb_j = embs[feature][j] * weights[feature]\n",
    "            text_similarities.append(cosine_similarity([emb_i], [emb_j])[0][0])\n",
    "        overall_similarity = scalar_similarity + sum(text_similarities)\n",
    "        sim_mat[i, j] = overall_similarity\n",
    "        sim_mat[j, i] = overall_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grph = nx.Graph()\n",
    "thres = 0.35\n",
    "for i, title in enumerate(mov_dataset[\"title\"]):\n",
    "    grph.add_node(i, title=title)\n",
    "for i in range(size):\n",
    "    for j in range(i + 1, size):\n",
    "        if sim_mat[i, j] > thres:\n",
    "            grph.add_edge(i, j, weight=sim_mat[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(list(grph.edges)).t().contiguous()\n",
    "edge_weight = torch.tensor([grph[u][v][\"weight\"] for u, v in grph.edges], dtype=torch.float)\n",
    "node_features = []\n",
    "for i in range(size):\n",
    "    scalar_features = np_array(\n",
    "        [\n",
    "            mov_dataset.iloc[i][\"is_adult\"] * weights[\"adult\"],\n",
    "            mov_dataset.iloc[i][\"original_language\"] * weights[\"original_language\"],\n",
    "            mov_dataset.iloc[i][\"year\"] * weights[\"year\"],\n",
    "        ]\n",
    "    )\n",
    "    text_features = []\n",
    "    for feature in [\"overview\", \"tagline\", \"genres\"]:\n",
    "        text_features.extend(embs[feature][i] * weights[feature])\n",
    "    node_features.append(np_hstack([scalar_features, text_features]))\n",
    "\n",
    "node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "grdata = Data(x=node_features, edge_index=edge_index, edge_attr=edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        return x\n",
    "model = GCN(node_features.shape[1],hidden_dim=64,output_dim=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "epochs = 8\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(grdata)\n",
    "    loss = torch.nn.functional.cross_entropy(out[grdata.train_mask], grdata.y[grdata.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_recs(prompt_titles,mov_dataset,gnn_model,data,k=4):\n",
    "    gnn_model.eval()\n",
    "    with torch.no_grad(): node_embeddings = gnn_model(data)\n",
    "    title_to_index = {row[\"title\"]: idx for idx, row in mov_dataset.iterrows()}\n",
    "    prompt_indices = [\n",
    "        title_to_index[title] for title in prompt_titles if title in title_to_index\n",
    "    ]\n",
    "    if not prompt_indices: raise ValueError(\"None of the provided titles were found in the dataset.\")\n",
    "    prompt_embeddings = node_embeddings[prompt_indices].cpu().numpy()\n",
    "    all_node_embeddings = node_embeddings.cpu().numpy()\n",
    "    similarities = cosine_similarity(prompt_embeddings, all_node_embeddings)\n",
    "    top_k_results = {}\n",
    "    for i, title in enumerate(prompt_titles):\n",
    "        if title in title_to_index:\n",
    "            node_idx = title_to_index[title]\n",
    "            node_similarities = similarities[i]\n",
    "            top_k_indices = node_similarities.argsort()[-(k + 1):][::-1]\n",
    "            top_k_indices = [idx for idx in top_k_indices if idx != node_idx][:k]\n",
    "            top_k_titles = [mov_dataset.iloc[idx][\"title\"] for idx in top_k_indices]\n",
    "            top_k_results[title] = top_k_titles\n",
    "    return top_k_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = [\"inception\"]\n",
    "sim_movs = get_similar_recs(inps,mov_dataset,model,grdata)\n",
    "for title, similar_titles in sim_movs.items():\n",
    "    print(f\"Top 4 similar titles to '{title}':\")\n",
    "    for similar_title in similar_titles:\n",
    "        print(f\"- {similar_title}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
